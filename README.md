<!-- # Paper Reading Group -->

Notes for papers presented during our paper reading sessions.

## Papers:
1. Tuning Frequency Bias of State Space Models [[paper](https://openreview.net/forum?id=wkHcXDv7cv)] [[slides](./Slides/tuning_freq_bias.pdf)]
1. Efficiently Modeling Long Sequences with Structured State Spaces [[paper](https://arxiv.org/pdf/2111.00396)] [[slides](./Slides/Deep%20State%20Space%20Models.pdf)]
1. Simplified State Space Layers for Sequence Modeling [[paper](https://arxiv.org/pdf/2208.04933)] [[slides](./Slides/Deep%20State%20Space%20Models.pdf)]
1. Mamba: Linear-Time Sequence Modeling with Selective State Spaces [[paper](https://arxiv.org/pdf/2312.00752)] [[slides](./Slides/Deep%20State%20Space%20Models.pdf)]
1. Representation Learning on Hyper-Relational and Numeric Knowledge Graphs with Transformers [[paper](https://arxiv.org/pdf/2305.18256)] [[slides](./Slides/Representation%20Learning%20on%20Hyper-Relational%20and%20Numeric%20Knowledge%20Graphs%20with%20Transformers.pdf)]
1. Chemical-Reaction-Aware Molecule Representation Learning [[paper](https://arxiv.org/pdf/2109.09888)] [[slides](./Slides/CHEMICAL-REACTION-AWARE%20MOLECULE%20REPRESENTATION%20LEARNING.pdf)]
1. Towards Foundation Models for Knowledge Graph Reasoning [[paper](https://arxiv.org/pdf/2310.04562)]
1. Pre-training Molecular Graph Representation with 3D Geometry [[paper](https://arxiv.org/pdf/2110.07728)] [[slides](./Slides/PRE-TRAINING%20MOLECULAR%20GRAPH%20REPRESENTATION%20WITH%203D%20GEOMETRY.pdf)]
1. AdaProp: Learning Adaptive Propagation for Graph Neural Network based Knowledge Graph Reasoning [[paper](https://arxiv.org/pdf/2205.15319)] [[slides](./Slides/Multi-modal%20Molecule%20Structure-text%20Model%20for%20Text-based%20Retrieval%20and%20Editing.pdf)]
1. Multi-modal Molecule Structure-text Model for Text-based Retrieval and Editing [[paper](https://arxiv.org/pdf/2212.10789)] [[slides](./Slides/Multi-modal%20Molecule%20Structure-text%20Model%20for%20Text-based%20Retrieval%20and%20Editing.pdf)]
1. Translation between Molecules and Natural Language [[paper](https://arxiv.org/pdf/2204.11817)] [[slides](./Slides/Text2Mol:%20Cross-Modal%20Molecule%20Retrieval%20with%20Natural%20Language%20Queries%20.pdf)]
1. SpecFormer: Spectral Graph Neural Networks Meet Transformers [[paper](https://arxiv.org/pdf/2303.01028)] [[slides](./Slides/SPECFORMER:%20SPECTRAL%20GRAPH%20NEURAL%20NETWORKS%20MEET%20TRANSFORMERS.pdf)]
1. FusionRetro: Molecule Representation Fusion via In-Context Learning for Retrosynthetic Planning [[paper](https://arxiv.org/pdf/2209.15315)] [[slides](./Slides/FusionRetro:%20Molecule%20Representation%20Fusion%20via%20In-Context%20Learning%20for%20Retrosynthetic%20Planning.pdf)]
1. Context-Enriched Molecule Representations Improve Few-Shot Drug Discovery [[paper](https://arxiv.org/pdf/2305.09481)]
1. Cooperative Graph Neural Networks [[paper](https://arxiv.org/pdf/2310.01267)]
1. Bi-Level Contrastive Learning for Knowledge Enhanced Molecule Representations [[paper](https://arxiv.org/pdf/2306.01631)] [[slides](./Slides/BI-LEVEL%20CONTRASTIVE%20LEARNING%20FOR%20KNOWL-%20EDGE%20ENHANCED%20MOLECULE%20REPRESENTATIONS.pdf)]
1. Equivariant Subgraph Aggregation Networks [[paper](https://arxiv.org/pdf/2110.02910)] [[slides](./Slides/Learning%20Rule-Induced%20Subgraph%20Representations%20for%20Inductive%20Relation%20Prediction%20.pdf)]
1. Prodigy: Enabling In-context Learning Over Graphs [[paper](https://arxiv.org/pdf/2305.12600)] [[slides](./Slides/Learning%20Rule-Induced%20Subgraph%20Representations%20for%20Inductive%20Relation%20Prediction%20.pdf)]
1. Learning Rule-Induced Subgraph Representations for Inductive Relation Prediction [[paper](https://arxiv.org/pdf/2408.07088)] [[slides](./Slides/Learning%20Rule-Induced%20Subgraph%20Representations%20for%20Inductive%20Relation%20Prediction%20.pdf)]
1. Knowledge graph-enhanced molecular contrastive learning with functional prompt [[paper](https://www.nature.com/articles/s42256-023-00654-0)] [[slides](./Slides/Knowledge%20graph-enhanced%20molecular%20contrastive%20learning%20with%20functional%20prompt%20.pdf)]
1. Multi-Grained Multimodal Interaction Network for Entity Linking [[paper](https://arxiv.org/pdf/2307.09721)] [[slides](./Slides/LESS%20IS%20MORE:%20ONE-SHOT-SUBGRAPH%20LINK%20PREDICTION%20ON%20LARGE-SCALE%20KNOWLEDGE%20GRAPH.pdf)]
1. Enhancing Molecular Property Prediction with Auxiliary Learning and Task-Specific Adaptation [[paper](https://arxiv.org/pdf/2401.16299)] [[slides](./Slides/Enhancing%20Molecular%20Property%20Prediction%20with%20Auxiliary%20Learning%20and%20Task-Specific%20Adaptation.pdf)]
1. PolyGCL: Graph Contrastive Learning via Learnable Spectral Polynomial Filters [[paper](https://openreview.net/pdf?id=y21ZO6M86t)] [[slides](./Slides/Enhancing%20Molecular%20Property%20Prediction%20with%20Auxiliary%20Learning%20and%20Task-Specific%20Adaptation.pdf)]
1. Less is More: One-Shot-Subgraph Link Prediction on Large-Scale Knowledge Graph [[paper](https://arxiv.org/pdf/2403.10231)] [[slides](./Slides/LESS%20IS%20MORE:%20ONE-SHOT-SUBGRAPH%20LINK%20PREDICTION%20ON%20LARGE-SCALE%20KNOWLEDGE%20GRAPH.pdf)]
1. Vision Transformers Need Registers [[paper](https://arxiv.org/abs/2309.16588)]
2. Denoising Diffusion Probabilistic Models [[paper](https://arxiv.org/pdf/2006.11239)]
3. Mitigating Memorisation in Diffusion Models [[paper](https://arxiv.org/pdf/2407.21720)]
4. Interpreting CLIP's Image Representation via Text-Based Decomposition [[paper](https://arxiv.org/pdf/2310.05916)]
5. Diffuse, Attend, and Segment: Unsupervised Zero-Shot Segmentation using Stable Diffusion [[paper](https://arxiv.org/pdf/2308.12469)]
6. Do Transformers Really Perform Bad for Graph Representation? (Graphormer) [[paper](https://arxiv.org/pdf/2106.05234)] [[slides](./Slides/Representation%20Learning%20on%20Hyper-Relational%20and%20Numeric%20Knowledge%20Graphs%20with%20Transformers.pdf)]
7. Rank-N-Contrast [[paper](https://openreview.net/pdf?id=WHedsAeatp)] [[slides](./Slides/BI-LEVEL%20CONTRASTIVE%20LEARNING%20FOR%20KNOWL-%20EDGE%20ENHANCED%20MOLECULE%20REPRESENTATIONS.pdf)]
8. EGRU [[paper](https://arxiv.org/pdf/2206.06178)]
9. Deep Bidirectional Language-Knowledge Graph Pretraining (DRAGON) [[paper](https://arxiv.org/pdf/2210.09338)] [[slides](./Slides/PRE-TRAINING%20MOLECULAR%20GRAPH%20REPRESENTATION%20WITH%203D%20GEOMETRY.pdf)]
10. Resurrecting Recurrent Neural Networks for Long Sequences (LRU) [[paper](https://arxiv.org/pdf/2303.06349)]
11. Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models [[paper](https://arxiv.org/pdf/2402.19427)]
12. Linguistic Binding in Diffusion Models [[paper](https://openreview.net/pdf?id=AOKU4nRw1W)]
13. Evolutionary Optimization of Model Merging Recipes [[paper](https://arxiv.org/pdf/2403.13187)] [[slides](./Slides/LLM%20Merging%20Paper%20presentations.pdf)]
14. Editing Models with Task Arithmetic [[paper](https://arxiv.org/pdf/2212.04089)] [[slides](./Slides/LLM%20Merging%20Paper%20presentations.pdf)]
15. WARM: On the Benefits of Weight Averaged Reward Models [[paper](https://arxiv.org/pdf/2401.12187)] [[slides](./Slides/LLM%20Merging%20Paper%20presentations.pdf)]
16. Rewarded Soups: Towards Pareto-Optimal Alignment by Interpolating Weights Fine-Tuned on Diverse Rewards [[paper](https://arxiv.org/pdf/2306.04488)] [[slides](./Slides/LLM%20Merging%20Paper%20presentations.pdf)]
17. Arcee's MergeKit: A Toolkit for Merging Large Language Models [[paper](https://arxiv.org/pdf/2403.13257)] [[slides](./Slides/LLM%20Merging%20Paper%20presentations.pdf)]
18. TIES-Merging: Resolving Interference When Merging Models [[paper](https://arxiv.org/pdf/2306.01708)] [[slides](./Slides/LLM%20Merging%20Paper%20presentations.pdf)]
19. LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition [[paper](https://arxiv.org/pdf/2307.13269)] [[slides](./Slides/LLM%20Merging%20Paper%20presentations.pdf)]
20. ZipIt! Merging Models from Different Tasks without Training [[paper](https://arxiv.org/pdf/2305.03053)] [[slides](./Slides/LLM%20Merging%20Paper%20presentations.pdf)]
21. Model Ratatouille: Recycling Diverse Models for Out-of-Distribution Generalization [[paper](https://arxiv.org/pdf/2212.10445)] [[slides](./Slides/LLM%20Merging%20Paper%20presentations.pdf)]
22. Text2Mol: Cross-Modal Molecule Retrieval with Natural Language Queries [[paper](https://aclanthology.org/2021.emnlp-main.47.pdf)] [[slides](./Slides/Text2Mol:%20Cross-Modal%20Molecule%20Retrieval%20with%20Natural%20Language%20Queries%20.pdf)]
23. MOPO: Model-based Offline Policy Optimization [[paper](https://arxiv.org/pdf/2005.13239)] [[notes](./MOPO/MOPO%20Model%20based%20Offline%20Policy%20Optimization.html)]
24. DETR: End-to-End Object Detection with Transformers [[paper](https://arxiv.org/pdf/2005.12872)] [[notes](./DETR/DETR:%20End-to-End%20Object%20Detection%20with%20Transformers.html)]
25. Efficient Adaptation for End-to-End Vision-Based Robotic Manipulation [[paper](https://openreview.net/pdf?id=CVN5cZBFFFG)] [[notes](./Efficient%20adaption%20for%20end%20to%20end%20Vision%20Based%20Robotic%20Manipulation%20/Efficient%20adaption%20for%20end%20to%20end%20Vision%20Based%20Robotic%20Manipulation.html)]
26. PipeDream: Generalized Pipeline Parallelism for DNN Training [[paper](https://arxiv.org/pdf/1806.03377)] [[notes](./PipeDream/PipeDream.html)]
27. Lottery Ticket Hypothesis [[paper](https://arxiv.org/pdf/1803.03635)] [[notes](./LTH/Lottery%20Ticket%20Hypothesis%2072c1972c2b9547a1be108c45c99d9774.html)]
28. Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies [[paper](https://arxiv.org/pdf/1611.01368)] [[notes](./Syntax%20and%20Structure%20in%20NLP/Syntax%20and%20Structure%20in%20NLP.html#assessing-the-ability-of-lstms-to-learn-syntax-sensitive-dependencies-tal-linzen-emmanuel-dupoux-yoav-goldberg)]
29. Designing and Interpreting Probes with Control Tasks [[paper](https://arxiv.org/pdf/1909.03368)] [[notes](./Syntax%20and%20Structure%20in%20NLP/Syntax%20and%20Structure%20in%20NLP.html#designing-and-interpreting-probes-with-control-tasks-john-hewitt--percy-liang)]
30. What Does BERT Learn about the Structure of Language? [[paper](https://arxiv.org/pdf/1906.04341)] [[notes](./Syntax%20and%20Structure%20in%20NLP/Syntax%20and%20Structure%20in%20NLP.html#what-does-bert-learn-about-the-structure-of-language-ganesh-jawahar-beno%C3%AEt-sagot-djam%C3%A9-seddah)]
31. GNN [[notes](./GNN-1/Graph%20Neural%20Networks%2065e8b918487d47f9b54b48d11207c8c8.html)]
32. Universal Adversarial Triggers [[paper](https://arxiv.org/pdf/1908.07125)] [[notes](./UAT/Adversarial-Machine-Learning.html)]
33. Confidence-Aware Learning for Deep Neural Networks (CRL) [[paper](https://arxiv.org/pdf/2007.01458)] [[notes](./Confidence-Aware%20Learning/Confidence%20Aware%20Learning%20for%20Deep%20Neural%20Networks%205080dd3c7bff4d6bbd44632448b1de31.html)]
34. A How-to-Model Guide for Neuroscience [[paper](https://www.eneuro.org/content/eneuro/7/1/ENEURO.0352-19.2019.full.pdf)] [[notes](./A%20How-to-Model%20Guide%20for%20Neuroscience/A%20How-to-Model%20Guide%20for%20Neuroscience.html)]
35. Neural ODEs [[paper](https://arxiv.org/pdf/1806.07366)] [[notes](./Neural_ODEs/Neural_ODEs.html)]
36. Model based Reinforcement Learning [[notes](./MBRL/Model%20Based%20Reinforcement%20Learning%207b98a25f0aa8434ca36d783dbbf60ec1.html)]
37. Learning to describe scenes with programs [[paper](https://openreview.net/pdf?id=SyNPk2R9K7)] [[notes](./Scenes%20with%20Programs/LEARNING%20TO%20DESCRIBE%20SCENES%20WITH%20PROGRAMS.html)]
38. DeepSynth: Automata Synthesis for Automatic Task Segmentation in RL [[paper](https://arxiv.org/pdf/1911.10244)] [[notes](./Automata%20Synthesis%20for%20RL/DeepSynth%20Automata%20Synthesis%20for%20Automatic%20Task%20Se%20956bdaa7e08c423aa97f319b469790d3.html)]
39. Model free conventions in MARL with Heterogeneous Preferences [[paper](https://arxiv.org/pdf/2010.09054)] [[notes](./Model%20free%20conventions%20in%20MARL%20with%20Heterogeneous%20Preferences/Model%20free%20conventions%20in%20MARL%20with%20Heterogeneous%20Preferences.html)]
40. Accelerating Reinforcement Learning with Learned Skill Priors [[paper](https://arxiv.org/pdf/2010.11944)] [[notes](./Accelerating%20Reinforcement%20Learning%20with%20Learned%20Skill%20Priors/Accelerating%20Reinforcement%20Learning%20with%20Learned%20S%2055f74821b841411e9b7695dd6cab9440.html)]
41. Progressive Domain Adaptation for Object Detection [[paper](https://arxiv.org/pdf/1910.11319)] [[notes](./Progressive%20Domain%20Adaptation%20for%20Object%20Detection/Progressive%20Domain%20Adaptation%20for%20Object%20Detection%20478798eacb8b477e92629c95ae306a49.html)]
42. Convolutional Networks with Adaptive inference Graphs [[paper](https://arxiv.org/pdf/1711.11503)] [[notes](./Convolutional%20Networks%20with%20Adaptive%20Inference%20Graph/Convolutional%20Networks%20with%20Adaptive%20Inference%20Gra%205c731fbfed5b4f93b6b49bc30f331d18.html)]
